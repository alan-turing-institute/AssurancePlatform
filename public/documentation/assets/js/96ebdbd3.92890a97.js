"use strict";(self.webpackChunktea_docs=self.webpackChunktea_docs||[]).push([[8634],{3409:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>n,toc:()=>h});const n=JSON.parse('{"id":"docs/curriculum/standalone/assurance-ecosystem","title":"Understanding the Assurance Ecosystem","description":"An introduction to the broader AI assurance ecosystem and key actors","source":"@site/docs/docs/curriculum/standalone/assurance-ecosystem.md","sourceDirName":"docs/curriculum/standalone","slug":"/docs/curriculum/standalone/assurance-ecosystem","permalink":"/documentation/docs/curriculum/standalone/assurance-ecosystem","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"learning-modules","permalink":"/documentation/tags/learning-modules"}],"version":"current","lastUpdatedBy":"Christopher Burr","sidebarPosition":1,"frontMatter":{"title":"Understanding the Assurance Ecosystem","description":"An introduction to the broader AI assurance ecosystem and key actors","level":"trainee","estimated_time":"30-40 minutes","sidebar_position":1,"sidebar_label":"The Assurance Ecosystem","tags":["learning-modules"]},"sidebar":"teaSidebar","previous":{"title":"Standards and their role in assurance","permalink":"/documentation/docs/curriculum/standalone/standards"},"next":{"title":"Section Overview","permalink":"/documentation/docs/technical-guide/"}}');var i=t(6070),a=t(4409);const r={title:"Understanding the Assurance Ecosystem",description:"An introduction to the broader AI assurance ecosystem and key actors",level:"trainee",estimated_time:"30-40 minutes",sidebar_position:1,sidebar_label:"The Assurance Ecosystem",tags:["learning-modules"]},o="Understanding the Assurance Ecosystem",c={},h=[{value:"Why is Assurance Important",id:"why-is-assurance-important",level:2},{value:"Justified Trust",id:"justified-trust",level:2},{value:"Key Actors, Roles, and Responsibilites",id:"key-actors-roles-and-responsibilites",level:2},{value:"Assuring different subject matter",id:"assuring-different-subject-matter",level:2}];function l(e){const s={a:"a",admonition:"admonition",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"understanding-the-assurance-ecosystem",children:"Understanding the Assurance Ecosystem"})}),"\n",(0,i.jsxs)(s.p,{children:["In 2021, the UK Government's\n",(0,i.jsx)(s.a,{href:"https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation",children:"Centre for Data Ethics and Innovation"}),"\n(now the Responsible Technology Adoption Unit) released their\n",(0,i.jsx)(s.a,{href:"https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem",children:"AI Assurance Roadmap"}),".\nThis publication set an agenda and series of recommendations for how to build\nand govern an effective AI Assurance ecosystem."]}),"\n",(0,i.jsx)(s.p,{children:"In the context of AI, we can think of an assurance ecosystem as the framework or\nenvironment that encompasses the methods, tools, roles, responsibilities,\nstakeholders (and relationships between them) that collectively work towards\nensuring AI systems are designed, developed, deployed, and used in a trustworthy\nand ethical manner. As such, it is an emerging concept, which is currently only\nloosely defined but can, nevertheless, help us address the challenges posed by\nAI technologies and maximise their opportunities."}),"\n",(0,i.jsx)(s.admonition,{title:"UK Government's AI Assurance Ecosystem",type:"info",children:(0,i.jsxs)(s.p,{children:["The following is based on and adapted from the Centre for Data Ethics and Innovation's AI Assurance Guide, which extends their original roadmap and seeks to clarify the scope of an assurance ecosystem as it pertains to AI. We consider some of the core concepts of the CDEI's guide, focusing on the parts that are relevant to the TEA platform. For further information, please visit their site: ",(0,i.jsx)(s.a,{href:"https://cdeiuk.github.io/ai-assurance-guide/",children:"https://cdeiuk.github.io/ai-assurance-guide/"})]})}),"\n",(0,i.jsx)(s.h2,{id:"why-is-assurance-important",children:"Why is Assurance Important"}),"\n",(0,i.jsx)(s.p,{children:"Data-driven technologies, such as artificial intelligence, have a complex\nlifecycle. In some cases, this complexity is further heightened by the scale at\nwhich a system is deployed (e.g. social media platforms with international\nreach)."}),"\n",(0,i.jsxs)(s.p,{children:["The scale and complexity of certain data-driven technologies has already been\nclearly communicated by others, such as\n",(0,i.jsx)(s.a,{href:"https://anatomyof.ai",children:"this excellent infographic"})," from the AI Now Institute\nshowing the many societal impacts and touch points that occur in the development\nof Amazon\u2019s smart speaker. Therefore, it is not necessary to revisit this point\nhere. However, it is important to explain why this complexity and scale matters\nfor the purpose of trustworthy and ethical assurance. There are three\n(well-rehearsed) reasons that are salient within the context of the assurance\necosystem:"]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsx)(s.li,{children:"Complexity: as the complexity of a system increases it becomes harder to\nmaintain transparency and explainability."}),"\n",(0,i.jsx)(s.li,{children:"Scalability: the risk of harm increases proportional to the scale of a\nsystem, and mechanisms for holding people or organisations accountable become\nharder to implement."}),"\n",(0,i.jsx)(s.li,{children:"Autonomous behaviour: where data-driven technologies are used to enable\nautonomous behaviour, opportunities for responsible human oversight are\nreduced."}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"justified-trust",children:"Justified Trust"}),"\n",(0,i.jsx)(s.p,{children:"As discussed at the start of this section, assurance is about building trust."}),"\n",(0,i.jsx)(s.p,{children:"But there is a further concept, related to trust, which is vital for assurance:\ntrustworthiness."}),"\n",(0,i.jsx)(s.p,{children:"As the CDEI's guide acknowledges:"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:['"when we talk about trustworthiness, we mean whether something is deserving of\npeople\u2019s trust. On the other hand, when we talk about trust, we mean whether\nsomething is actually trusted by someone, which might be the case even if it\nis not in fact trustworthy." A successful relationship built on justified\ntrust requires ',(0,i.jsx)(s.strong,{children:"both"})," trust and trustworthiness: ",(0,i.jsx)(s.strong,{children:"Trust without\ntrustworthiness = misplaced trust."})," If we trust technology, or the\norganisations deploying a technology when they are not in fact trustworthy, we\nincur potential risks by misplacing our trust. ",(0,i.jsx)(s.strong,{children:"Trustworthy but not trusted =\n(unjustified) mistrust."})," If we fail to trust a technology or organisation\nwhich is in fact trustworthy, we incur the opportunity costs of not using good\ntechnology."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(4163).A+"",width:"1920",height:"1280"})}),"\n",(0,i.jsxs)(s.p,{children:["_Figure 1. The relationship between three parties required to establish justified trust. ",(0,i.jsx)(s.a,{href:"https://cdeiuk.github.io/ai-assurance-guide/trust",children:"https://cdeiuk.github.io/ai-assurance-guide/trust"})]}),"\n",(0,i.jsxs)(s.p,{children:["The concept of justified trust is, understandably, an integral part of\n",(0,i.jsx)(s.em,{children:"trustworthy"})," and ethical assurance."]}),"\n",(0,i.jsx)(s.p,{children:"We can turn to the moral philosopher, Onora O\u2019Neill, for a clear articulation of\nwhy this is so,"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"\u201c[...] if we want a society in which placing trust is feasible we need to look\nfor ways in which we can actively check one another\u2019s claims."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"But, she continues,"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"\u201c[...] active checking of information is pretty hard for many of us.\nUnqualified trust is then understandably rather scarce.\u201d"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"The CDEI's Assurance guide identifies two problems that help explain why active\nchecking is challenging:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"An information problem:"})," organisations face difficulties in continuously\nevaluating AI systems and acquiring the evidence base that helps establish\nwhether a system is trustworthy (i.e. whether users or stakeholders should\nplace trust in the system)"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"A communication problem:"})," once they have established the trustworthiness of\nthe system, there are additional challenges to communicate this to relevant\nstakeholders and users such that they trust the claims being made."]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["An effective assurance ecosystem should help actors overcome these issues to\nestablish ",(0,i.jsx)(s.em,{children:"justified trust"}),". Let's take a look at some of the key actors in an\nassurance ecosystem."]}),"\n",(0,i.jsx)(s.h2,{id:"key-actors-roles-and-responsibilites",children:"Key Actors, Roles, and Responsibilites"}),"\n",(0,i.jsx)(s.p,{children:'AI is often described as sociotechnical. Here, the term "sociotechnical" is used\nto emphasise how the design, development, deployment, and use of AI is deeply\nintertwined with social systems and practices, and influenced by a wide array of\nhuman and organisational factors. Because of this, any list of actors, and their\nvarious roles and responsibilities will fall short in a number of dimensions.\nHowever, the following graphic provides us with a good starting point for\nunderstanding the key actors in an assurance ecosystem.'}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"This diagram depicts the AI assurance ecosystem, illustrating interactions between AI supply chain participants, AI Assurance Service Providers, Independent Researchers, and Supporting Structures like regulators and standards bodies.",src:t(5755).A+"",width:"1394",height:"1438"})}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsxs)(s.em,{children:["Figure 2. Key actors in the AI Assurance Ecosystem. Reprinted from CDEI (2023)\nAI Assurance Guide. ",(0,i.jsx)(s.a,{href:"https://cdeiuk.github.io/ai-assurance-guide/needs-and-responsibilities",children:"https://cdeiuk.github.io/ai-assurance-guide/needs-and-responsibilities"})]})}),"\n",(0,i.jsx)(s.p,{children:"As the diagram depicts, certain actors have a direct influence into the supply\nchain for AI systems. These are known as 'assurance users'. For instance,\norganisations may have dedicated teams internally who are responsible for\nquality assurance of products or services (e.g. compliance with safety\nstandards, adherence to data privacy and protection legislation). However, there\nis a growing marketplace of independent 'assurance service providers' who offer\nconsultancy or services to other companies or organisations.[^market]"}),"\n",(0,i.jsx)(s.p,{children:"These users and providers are further supported by structures including\ngovernments, regulators, standards bodies, and accreditation/professional\nbodies. That is, the relationship between users and provides does not operate in\na vacuum, but within a complex environment of legislation, regulation, and\ngeneral norms and best practices."}),"\n",(0,i.jsxs)(s.p,{children:["[^market]:\nFor example, ",(0,i.jsx)(s.a,{href:"https://www.credo.ai/",children:"Credo AI"})," offer a paid-for service that\ncomprises an interactive dashboard and set of tools to help companies comply\nwith existing and emerging policies and regulation. Whereas, other\norganisations, such as the\n",(0,i.jsx)(s.a,{href:"https://www.adalovelaceinstitute.org/project/algorithmic-impact-assessment-healthcare/",children:"Ada Lovelace Institute"}),"\nhave developed open-source tools for teams to implement within their own\nprojects."]}),"\n",(0,i.jsx)(s.p,{children:"This is a helpful starting point for gaining some purchase on the complex set of\ninteracting roles and responsibilities that collectively make up what is\nadmittedly a hard to delineate assurance ecosystem. Because the TEA platform\nemphasises the importance of ethical reflection and deliberation, the resources\nand materials are likely to be of specific interest to the following actors:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Researchers"}),"\n",(0,i.jsx)(s.li,{children:"Journalists/Activists"}),"\n",(0,i.jsx)(s.li,{children:"Internal Assurance Teams"}),"\n",(0,i.jsx)(s.li,{children:"Developers"}),"\n",(0,i.jsx)(s.li,{children:"Frontline User"}),"\n",(0,i.jsx)(s.li,{children:"Affected Individuals"}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"assuring-different-subject-matter",children:"Assuring different subject matter"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"Whether someone needs to build confidence in the trustworthiness of different\nproducts, systems, processes, organisations or people will influence the type\nof information required, and the techniques required to provide assurance.\nThis is because different products, systems, processes, organisations and\npeople have different aspects that affect their trustworthiness i.e. they have\ndifferent assurance subject matters."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"Whether a frontline user of a system is confident in using the system will\ndepend on a wide variety of factors. If the system is a medical device, and the\nfrontline user is a healthcare professional, safety and accuracy may be primary\nconcerns. However, if the system is an algorithmic decision-support tool, the\nfrontline user may care more about the explainabilty of the system."}),"\n",(0,i.jsx)(s.p,{children:"Assurance needs, therefore, vary depending on what's being assured\u2014products,\nsystems, processes, organisations, or individuals. Simple products like kettles\nmay have straightforward, measurable assurance criteria, whereas complex systems\nlike AI necessitate nuanced, multi-dimensional assurance approaches due to their\nvaried subject matters like robustness, accuracy, bias, explainability, and\nothers. As previously noted, the complexity of AI arises because of the\nsociotechnical interactions between technical, organisational, and human\nfactors. Ethical principles such as fairness, privacy, and accountability are\nintertwined with these interactions, necessitating comprehensive assurance\nmechanisms."}),"\n",(0,i.jsx)(s.p,{children:"While not specifically designed to address ethical principles, the following\ndiagram from the CDEI's Assurance Guide can help elucidate some of the reasons\nwhy trustworthy and ethical assurance can be challenging."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:t(2143).A+"",width:"1920",height:"1280"})}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.em,{children:"Figure 3. A graphic showing the four\ndimensions of assurance subject matter: unobservable/observable,\nsubjective/objective, ambiguous/explicit, uncertain/certain."})})]})}function d(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},5755:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/actors-52df59b322f30965225464bf28d3a813.png"},4163:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/justified-trust-98146226b1b4db1f22a9da28c3dc7654.png"},2143:(e,s,t)=>{t.d(s,{A:()=>n});const n=t.p+"assets/images/subject-matter-8fd5977f0885f4edb7eef5972428dcd9.png"},4409:(e,s,t)=>{t.d(s,{R:()=>r,x:()=>o});var n=t(758);const i={},a=n.createContext(i);function r(e){const s=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),n.createElement(a.Provider,{value:s},e.children)}}}]);

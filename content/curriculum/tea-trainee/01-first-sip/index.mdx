---
title: 'Introduction'
description: Experience how structured arguments build trust in AI systems
---

import LearningObjectives from '@/components/docs/curriculum/learning-objectives';
import ModuleHeader from '@/components/docs/curriculum/module-header';
import { firstSipObjectives } from './objectives';

export const moduleMetadata = {
  title: 'Introduction',
  duration: '20-30 minutes',
  prerequisites: [],
};

<ModuleHeader metadata={moduleMetadata} />

Imagine you're about to use a new AI system that screens job applications at your company. The vendor claims it's "fair and non-discriminatory".

How can you be sure that the vendor's claim is true? What reasoning has been provided to assure you that it won't discriminate against certain groups? What evidence would convince you?

In this module, you'll explore an approach to answering these questions known as **Trustworthy and Ethical Assurance** (or TEA for short). But rather than starting with definitions and theory, we're going to jump straight into a practical example.

<LearningObjectives
  title="Learning Objectives"
  variant="card"
  objectives={firstSipObjectives}
/>
